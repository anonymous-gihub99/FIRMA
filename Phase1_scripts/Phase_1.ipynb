{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3018d0-6155-48d5-9465-7a9ebd3a11c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Building 'rouge-score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge-score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Phase 1: Dataset Curation and Baseline Implementation with AI4M Dataset\n",
    "# Using real Lean 4 formal-informal pairs and Qwen models\n",
    "\n",
    "# Cell 1: Install required packages\n",
    "!pip install -q torch transformers datasets peft bitsandbytes accelerate\n",
    "!pip install -q sentence-transformers faiss-gpu evaluate rouge-score\n",
    "!pip install -q sentencepiece protobuf tqdm networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0cb320a-9f59-4e59-9961-d592e46e1db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 1: MANUAL DATASET & QWEN BASELINES\n",
      "============================================================\n",
      "\n",
      "✓ CUDA Available\n",
      "  GPU 0: NVIDIA L4 (23.57 GB)\n",
      "    → Detected L4 GPU, using standard settings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 2: Setup environment and check GPUs\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set environment variables for efficient GPU usage\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 1: MANUAL DATASET & QWEN BASELINES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check available GPUs\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n✓ CUDA Available\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "        print(f\"  GPU {i}: {gpu_name} ({gpu_memory:.2f} GB)\")\n",
    "        \n",
    "        # Adjust batch size based on GPU memory\n",
    "        if gpu_memory < 16:  # T4 GPU\n",
    "            print(\"    → Detected T4 GPU, using optimized settings\")\n",
    "            os.environ['BATCH_SIZE'] = '1'\n",
    "        elif gpu_memory < 25:  # L4 GPU\n",
    "            print(\"    → Detected L4 GPU, using standard settings\")\n",
    "            os.environ['BATCH_SIZE'] = '2'\n",
    "else:\n",
    "    print(\"⚠ No GPU available, will use CPU (very slow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9171ad6f-3f10-47b5-9d6b-259b0d86dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: DATASET ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Checking for dataset files...\n",
      "✓ Found train file: statements_part1.json\n",
      "✓ Found valid file: valid_clean.json\n",
      "✓ Found test file: test_clean.json\n",
      "\n",
      "Analyzing training data structure...\n",
      "  Total training samples: 702\n",
      "  Sample keys: ['informal_statement', 'formal_statement']\n",
      "\n",
      "  Sample pair:\n",
      "  Informal (informal_statement): For all odd $n$ show that $8 \\\\mid n^{2}-1$....\n",
      "  Formal (formal_statement): theorem exercise_1_27 {n : \\u2115} (hn : odd n) : 8 \\u2223 (n^2 - 1)...\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Check and Analyze Dataset Files\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: DATASET ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define data directory\n",
    "data_dir = Path(\"./math_alignment_dataset\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check for your manually extracted files\n",
    "print(\"\\nChecking for dataset files...\")\n",
    "\n",
    "# List all potential data files\n",
    "data_files = {\n",
    "    'train': ['statements_part1.json', 'train.json', 'train.jsonl'],\n",
    "    'valid': ['valid_clean.json', 'val.json', 'val.jsonl'],\n",
    "    'test': ['test_clean.json', 'test.json', 'test.jsonl']\n",
    "}\n",
    "\n",
    "found_files = {}\n",
    "for split, filenames in data_files.items():\n",
    "    for filename in filenames:\n",
    "        filepath = data_dir / filename\n",
    "        if filepath.exists():\n",
    "            found_files[split] = filepath\n",
    "            print(f\"✓ Found {split} file: {filename}\")\n",
    "            break\n",
    "    if split not in found_files:\n",
    "        print(f\"✗ No {split} file found\")\n",
    "\n",
    "# Analyze dataset structure\n",
    "if 'train' in found_files:\n",
    "    print(\"\\nAnalyzing training data structure...\")\n",
    "    with open(found_files['train'], 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        if content.strip().startswith('['):\n",
    "            # JSON array format\n",
    "            train_data = json.loads(content)\n",
    "        else:\n",
    "            # JSONL format\n",
    "            f.seek(0)\n",
    "            train_data = [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "    print(f\"  Total training samples: {len(train_data)}\")\n",
    "    if train_data:\n",
    "        print(f\"  Sample keys: {list(train_data[0].keys())}\")\n",
    "        \n",
    "        # Display sample\n",
    "        sample = train_data[0]\n",
    "        informal_key = None\n",
    "        formal_key = None\n",
    "        \n",
    "        # Detect keys\n",
    "        for key in ['informal_statement', 'informal_stmt', 'informal']:\n",
    "            if key in sample:\n",
    "                informal_key = key\n",
    "                break\n",
    "        \n",
    "        for key in ['formal_statement', 'formal_stmt', 'formal']:\n",
    "            if key in sample:\n",
    "                formal_key = key\n",
    "                break\n",
    "        \n",
    "        if informal_key and formal_key:\n",
    "            print(f\"\\n  Sample pair:\")\n",
    "            print(f\"  Informal ({informal_key}): {sample[informal_key][:100]}...\")\n",
    "            print(f\"  Formal ({formal_key}): {sample[formal_key][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4265b547-528d-4642-86dd-e00748ecb53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONFIGURING QWEN BASELINES\n",
      "============================================================\n",
      "Configuring for L4 GPU (24GB)...\n",
      "\n",
      "Baseline Configuration:\n",
      "  Fine-tuning model: Qwen/Qwen2.5-Math-7B\n",
      "  API model: Qwen/Qwen2.5-1.5B\n",
      "  Batch size: 4\n",
      "  Max length: 384\n",
      "  Data directory: math_alignment_dataset\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Configure baselines with Qwen models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFIGURING QWEN BASELINES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from baseline_implementation_manual import (\n",
    "    BaselineConfig,\n",
    "    DirectFineTuningBaseline,\n",
    "    RetrievalAugmentedBaseline,\n",
    "    CommercialAPIBaseline,\n",
    "    BaselineEvaluator\n",
    ")\n",
    "\n",
    "# Configure for available hardware\n",
    "config = BaselineConfig()\n",
    "config.data_dir = str(data_dir)\n",
    "\n",
    "# Adjust based on GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    if gpu_memory < 16:  # T4 GPU\n",
    "        print(\"Configuring for T4 GPU (15GB)...\")\n",
    "        config.batch_size = 1\n",
    "        config.gradient_accumulation = 32\n",
    "        config.max_length = 256\n",
    "        config.model_name = \"Qwen/Qwen2.5-Math-1.5B\"  # Smaller model for T4\n",
    "        config.api_model = \"Qwen/Qwen2.5-0.5B\"  # Tiny model for API\n",
    "        \n",
    "    elif gpu_memory < 25:  # L4 GPU\n",
    "        print(\"Configuring for L4 GPU (24GB)...\")\n",
    "        config.batch_size = 4\n",
    "        config.gradient_accumulation = 16\n",
    "        config.max_length = 384\n",
    "        config.model_name = \"Qwen/Qwen2.5-Math-7B\"\n",
    "        config.api_model = \"Qwen/Qwen2.5-1.5B\"\n",
    "    else:\n",
    "        print(\"Using full configuration...\")\n",
    "        config.batch_size = 4\n",
    "        config.gradient_accumulation = 8\n",
    "        config.model_name = \"Qwen/Qwen2.5-Math-7B\"\n",
    "        config.api_model = \"Qwen/Qwen2.5-3B\"\n",
    "\n",
    "print(f\"\\nBaseline Configuration:\")\n",
    "print(f\"  Fine-tuning model: {config.model_name}\")\n",
    "print(f\"  API model: {config.api_model}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Max length: {config.max_length}\")\n",
    "print(f\"  Data directory: {config.data_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86166f72-0dee-47c6-b409-ce8d96f6dc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE 1: DIRECT FINE-TUNING\n",
      "============================================================\n",
      "Initializing Qwen model with QLoRA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Loading Qwen/Qwen2.5-Math-7B...\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8207acd403549478464d767f77b24d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Starting training with Qwen2.5-Math...\n",
      "INFO:baseline_implementation_manual:Found training file: math_alignment_dataset/statements_part1.json\n",
      "INFO:baseline_implementation_manual:Found validation file: math_alignment_dataset/valid_clean.json\n",
      "INFO:baseline_implementation_manual:Loaded 702 pairs from math_alignment_dataset/statements_part1.json\n",
      "INFO:baseline_implementation_manual:Sample item keys: dict_keys(['informal', 'formal'])\n",
      "INFO:baseline_implementation_manual:Loaded 244 pairs from math_alignment_dataset/valid_clean.json\n",
      "INFO:baseline_implementation_manual:Sample item keys: dict_keys(['informal', 'formal'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 40,370,176 || all params: 7,655,986,688 || trainable%: 0.5273\n",
      "\n",
      "Starting training...\n",
      "This may take 20-30 minutes on T4, 10-15 minutes on L4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/220 01:03 < 3:48:46, 0.02 it/s, Epoch 0.09/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5: Train Direct Fine-tuning Baseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE 1: DIRECT FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    print(\"Initializing Qwen model with QLoRA...\")\n",
    "    direct_baseline = DirectFineTuningBaseline(config)\n",
    "    \n",
    "    print(\"\\nStarting training...\")\n",
    "    print(\"This may take 20-30 minutes on T4, 10-15 minutes on L4...\")\n",
    "    direct_baseline.train()\n",
    "    \n",
    "    print(\"✓ Direct fine-tuning complete!\")\n",
    "    \n",
    "    # Test the model\n",
    "    test_inputs = [\n",
    "        \"For all odd n show that 8 divides n^2 - 1\",\n",
    "        \"Prove that the square of any real number is non-negative\",\n",
    "        \"Show that if a group G has order p^n where p is prime, then G has a subgroup of order p\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTest translations:\")\n",
    "    for test_input in test_inputs[:1]:  # Test with first input\n",
    "        print(f\"\\nInput: {test_input[:80]}...\")\n",
    "        output = direct_baseline.generate(\n",
    "            f\"Translate to formal: {test_input}\\nFormal:\",\n",
    "            max_new_tokens=256\n",
    "        )\n",
    "        if \"Formal:\" in output:\n",
    "            output = output.split(\"Formal:\")[-1].strip()\n",
    "        print(f\"Output: {output[:150]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Direct fine-tuning failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Clear GPU memory\n",
    "if 'direct_baseline' in locals():\n",
    "    del direct_baseline\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64fe4127-7d52-4d90-b3a1-bed0281440ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE 2: RETRIEVAL-AUGMENTED\n",
      "============================================================\n",
      "Building retrieval system...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4650296a4e4139a7563e85e130734e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f18a8ea88142699bb5e809fdfaab80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3f8b7923b044ffa7f5345073e10213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3b2bb0b774417b858dcceda7cabbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec48c26743e40f6ba7ce0e3659d7545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f0477b51be4e69aca96e247a8036f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a30dfe96fa487a9804872e03ec33b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86121c22ecce4c6ab287cd68e2869c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f088926023e944b1806d34f529de964f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4e1ef7321c4744ab15d7748094ea0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5fafda1089406ba830d1525bcd5acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Building retrieval indices...\n",
      "INFO:baseline_implementation_manual:Found training file: math_alignment_dataset/statements_part1.json\n",
      "INFO:baseline_implementation_manual:Loaded 702 pairs for indexing\n",
      "INFO:baseline_implementation_manual:Computing embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dcbe4ff76b4657a32649442346c736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae825dea6ac14cc9bf78be4c6d07085f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead7b8c9a0e74eab90f5815724dbc469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4491ea2f87c44f088a561ed3dcddfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1b14543ea7416385370d48e8bc6858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309084a5af6040df8fcca8bda11bf2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af6432bc7384137829e7fcb6cc6b3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e76148f04864974a83e76f8c0132a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ec87cfdb104065839265a3448020dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bb786d084741388f5e7202f7352c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab65190d509749e59e239f4c6f5fdb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515d31ced8c544a093cdd02aa8833e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b708ca305ad1497c840032fd200c66e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256f75f09d314df2b50c4cf6ef1fa4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f0b67e5b4d45718886607e5929663b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee5269441494e9f8833a02da22a80ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2c1af5109f456bb19cc5e2af76fd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380fb7560e3e408a8608c72f8a9f7f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b1fbc1e2e4aa9af4c4dbaf87a1dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d3196f36e545d29b0444ef12d317ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5cbea7d2624519a934780109b13891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f58d7ca802a4a669d0a7a9a1b85709e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f531c30a8c467293462a96f93c8fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2be99927664f5c9182dfd89b731608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d92fd838f84de3996587e565e7276b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59ec0a1d6e543c18d5f757a3f1d5431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce927c295eb476fb303c9d81da56d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c7bd1db85645d99038ec2ffde9d4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835c4ce15ea045f49303bb6146c95a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20b4dd086d4445783af4d91bcd01d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165fdee65b6a44669380e7502b3c79d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4245252d0c0478593f28ccb312ecd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3e12e98dad4a9ea55e275762f4e6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7f7c4f167848c9a854e2e0a805db27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cd88d920724ec88bc7b6b258c347bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e600122af4c87bf1eab65f766522c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0921955982924bd5a5302875976ddd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e71f114bb044e87983145997fff2423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daad1fe18e1b4f43b58aba256da756e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d4a7cd4bf84ab9bfddac93c8f498f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be9777718d94447a5a58a542322f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368b1a6bab374f3383b790601a55663f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ed2b0f8dcb4323b9acebc9529f70cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68288b6d00ce41d3b25969fe177b9680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Building FAISS indices...\n",
      "INFO:baseline_implementation_manual:Indices saved to baseline_output/retrieval_augmented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Retrieval index built!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1761caea0047c9b6cc90a5e1d1068c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test retrieval:\n",
      "Input: theorem exercise_1_27 {n : ℕ} (hn : odd n) : 8 ∣ (n^2 - 1)\n",
      "Retrieved: For all odd $n$ show that $8 \\\\mid n^{2}-1$....\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Build Retrieval-Augmented Baseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE 2: RETRIEVAL-AUGMENTED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    print(\"Building retrieval system...\")\n",
    "    retrieval_baseline = RetrievalAugmentedBaseline(config)\n",
    "    retrieval_baseline.build_index()\n",
    "    \n",
    "    print(\"✓ Retrieval index built!\")\n",
    "    \n",
    "    # Test retrieval\n",
    "    test_formal = \"theorem exercise_1_27 {n : ℕ} (hn : odd n) : 8 ∣ (n^2 - 1)\"\n",
    "    result = retrieval_baseline.translate(test_formal, \"formal_to_informal\")\n",
    "    print(f\"\\nTest retrieval:\")\n",
    "    print(f\"Input: {test_formal}\")\n",
    "    print(f\"Retrieved: {result[:150]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Retrieval baseline failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "if 'retrieval_baseline' in locals():\n",
    "    del retrieval_baseline\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27db29ea-5169-4943-aa2a-ee71e8c53881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Loading API model: Qwen/Qwen2.5-1.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE 3: API BASELINE (QWEN)\n",
      "============================================================\n",
      "Loading Qwen/Qwen2.5-1.5B...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326dd4ce52da403983cea586a052766b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f31554bf27a48eb904dceb1218ef783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a885a226c5495d87064bea7466faaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6babccf4e6334565a8b1ab6d0d7054cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182438e558704e7fb94293549e013393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d20920c7bc4c7a8a04f8d2ee30e8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2187718d3bb84aa69053ad5875fbddf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API baseline ready!\n",
      "\n",
      "Test API translation:\n",
      "Input: The square of any real number is non-negative\n",
      "Output: For any real number x, the square of x (denoted as x^2) is greater than or equal to 0.\n",
      "\n",
      "Justification:\n",
      "\n",
      "1. I identified that the informal statement is...\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Setup API Baseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE 3: API BASELINE (QWEN)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    print(f\"Loading {config.api_model}...\")\n",
    "    api_baseline = CommercialAPIBaseline(config)\n",
    "    \n",
    "    print(\"✓ API baseline ready!\")\n",
    "    \n",
    "    # Test API baseline\n",
    "    test_informal = \"The square of any real number is non-negative\"\n",
    "    result = api_baseline.translate_with_cot(test_informal, \"informal_to_formal\")\n",
    "    print(f\"\\nTest API translation:\")\n",
    "    print(f\"Input: {test_informal}\")\n",
    "    print(f\"Output: {result[:150]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ API baseline setup failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "if 'api_baseline' in locals():\n",
    "    del api_baseline\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc43450-fe19-465d-9d41-4f021dbd473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert_score -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f2a53-dc3d-4a86-96cd-ef3248534709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION PHASE\n",
      "============================================================\n",
      "Starting comprehensive evaluation...\n",
      "This will evaluate all baselines on the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found test file: math_alignment_dataset/test_clean.json\n",
      "\n",
      "1. Evaluating Direct Fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Loading Qwen/Qwen2.5-Math-7B...\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531ee7b69f9441309172e733f2c13f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 40,370,176 || all params: 7,655,986,688 || trainable%: 0.5273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Evaluating direct_finetuning...\n",
      "INFO:baseline_implementation_manual:Found test file: math_alignment_dataset/test_clean.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded trained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating direct_finetuning: 100%|██████████| 50/50 [46:25<00:00, 55.72s/it]\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45583d069c04dc89409276c5556ffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8485197f744135864967beaf9e0f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d383d9fe0347b4b204b1c197139701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f246452be57b423db5c0d24f91f7c041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc9f9fe6b2d4896b5f2771a8d437ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f1ab7b2c3d4b3eba8dc6c1b42d922b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:baseline_implementation_manual:Results saved to baseline_output/evaluation_results/direct_finetuning_results.json\n",
      "INFO:baseline_implementation_manual:Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Evaluating Retrieval-Augmented...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:baseline_implementation_manual:Evaluating retrieval_augmented...\n",
      "INFO:baseline_implementation_manual:Found test file: math_alignment_dataset/test_clean.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded existing indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d89a530d44c48e4a18b074062999f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b82013b647a4ec29b8a118dcdba266b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56608f83a2d046f29967f5578d83855a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707cf4927cf04a11af2530eb9ca7aa1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c43e95be05445ea9b0e04a5b599319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a32f0bbf3ff46a6b4d9717a3d4123bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40726e6d0d44692b4443ca535559c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf88bae51254e55abb74b206d1bbe09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:   8%|▊         | 4/50 [00:00<00:01, 35.97it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ab8852aee24ccda137fee81d1ecdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b147867cbe4f77899ac76fa0639ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac014fe29f344e3b9e8523e4d06c907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b7924a78564fd99bf5dd197cabc85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cdb669fbfa464d93172b928d8ddad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a793ae47d4d44c99bfe4d5385294352a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1c0f226f834b1283c79030731fa4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8223dc7e91594240adcfa2c041d9c9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7f9abc21d945deb2ef9fb1dc6aae22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a654f6e99d54dacaf9bc15fca5bbce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  18%|█▊        | 9/50 [00:00<00:01, 38.55it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae1648e0b1a4dfc887807b3e726d3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd62987b5e344f0b0c222b1ca9164f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3129045ba0644309bbad0f9f40b42663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8873d3483e43cf882a590f9c7a5485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a9585d60de40a8abe0a31a61a3bbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae9a554ea6041dea68c9032f80d37f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75082e8abf2d4fa48bac015ca82430f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1ee9f77ac443338ae01e88754966be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73d1fbf311a4aaab1c5c9650eadff60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b8fce25daf45bd82dc103a3552186f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  28%|██▊       | 14/50 [00:00<00:00, 40.91it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2820e97a0c94310965589ae1f3b1b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fd63c4918d4919973a0b99de6da053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bad2de110b4bcb9db9c2692c560fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e9a256f383485aaa7db8a26f7d3b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e45d52c6f124321b66ae6a79fffa22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b1d30bb9504b38940535daaac4eabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939ffbe519d94ff38d14507e6c403163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaae1a0627bc46f3a9f2b0d97a15f48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98cbf88c3ed4c4fa577543a5ad71fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db307cd6d4fb423d88a293e8ed41b740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  38%|███▊      | 19/50 [00:00<00:00, 42.32it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a034bed86e0d44ee9d0bcfcc11075650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37a072e539441da9056d1c2465bebf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897c95be246b4ea89f252741d6d1ce20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81dcad87af54757a0d24a8d367eebb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ae0a5c25ea48edba80151899f66830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c142f4978be84709930e363876f48e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644e5e358f0440a08f503ec18f927fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74eece783c774b58a37973b73dff8332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9a4176241d4000a75da09408ab18d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7aeb8e6a5642e69e10c911675c24ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  48%|████▊     | 24/50 [00:00<00:00, 43.05it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f58f20ff094d73b79c1506b72fe010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2faee3e1e62e4254b721b5cfac3ad8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74aab57a94048eeaa169011eee845c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec7d3a4160944148241046017a8ea7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f39ed75a53a458094745a2b10c890f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248917aadaa7460d99cbe60998d26f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5407d931124aaa9b34aa6af8927b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc23e10212694f39b2670527481e248a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdff0451bc64bd7b29a6546c035e608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6b2e6375b44ba3a1383dafd2eed3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  58%|█████▊    | 29/50 [00:00<00:00, 43.34it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430ffde30d6c44c48393ff39778ea955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae2778f59f545b296952d1192ed79c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6b7091f9e241b699d0237a61f2fe1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29884ade1684d31816d5722c8888316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1cf017008c4d348594c5500cc7ec66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30795a76c2ba4afba3785d0dd6360b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c926746be45464885495db77b97426d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d97300e90774ca7b90843d597bcde7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b7374eb2f4413987f21739c1be3b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01208dc4634446ccbc9a55fc19e25cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  68%|██████▊   | 34/50 [00:00<00:00, 43.65it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bd0ef6a610484a901e330914460835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323a8ce3ef1644b6bb56beefee86f962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987f7676c487430db5ab95a815f58c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4137a6bc51574df5a6ca3d5b8206d8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745c69a55bab40df800daea61957bdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a91a99cdfe4b168b1495f05ad67d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e6e14146fd44b397560ec192fd1eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312081ff8cbb40159ccc919992eeda6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d298fe9678c4817a65e18f6653ada91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e07c6bc59d4eccad2c5b828efc4576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  78%|███████▊  | 39/50 [00:00<00:00, 43.79it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6bb473d0e8405d9419937fcc2128af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b4d335b54e42e59cdf2d3f33e98b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f5f577d3934e5cbef6bc9129448557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c983d88cd074cce82794a3fe6a54282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ea0ae9fec8495682eaac0836fb2991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352688efb8c54800a17342b3cbfb15c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db5022b74c64308be69cab55d17dbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671fd7f4fdba4fd2a19a322352d1b680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2b359a1f8442f38100abf9fbeba32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dd3c30576f4f909188b3fc4599a3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  88%|████████▊ | 44/50 [00:01<00:00, 44.13it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc4cc85418f4d5bbc87b35e4a968439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3de6d296f33420784ddb73eecf7f5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d929c1cf334a69ac59e3c0e746e7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef91bf0c34504bfc813bf62e36e22f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce02db455d4048fea1450daf3ed29f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816bc661c7004479997cc9fb99b86f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bfd45257c14436bca8994da8ea2f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe9b3acdc7e4da4bf63a3a2ab3b6dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8997dcc28fa425ab130f9a3ca0476cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe3055f7bc34d42b12f64192a181e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented:  98%|█████████▊| 49/50 [00:01<00:00, 43.75it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3327357e4724f6dbd88c0044e622791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1368c8da5744ce5bf49334b156fa26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrieval_augmented: 100%|██████████| 50/50 [00:01<00:00, 42.88it/s]\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:baseline_implementation_manual:Results saved to baseline_output/evaluation_results/retrieval_augmented_results.json\n",
      "INFO:baseline_implementation_manual:Loading API model: Qwen/Qwen2.5-1.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Evaluating API Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "INFO:baseline_implementation_manual:Evaluating api_baseline...\n",
      "INFO:baseline_implementation_manual:Found test file: math_alignment_dataset/test_clean.json\n",
      "Evaluating api_baseline: 100%|██████████| 50/50 [13:06<00:00, 15.74s/it]\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:baseline_implementation_manual:Results saved to baseline_output/evaluation_results/api_baseline_results.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Evaluate All Baselines\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION PHASE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    print(\"Starting comprehensive evaluation...\")\n",
    "    print(\"This will evaluate all baselines on the test set\")\n",
    "    \n",
    "    evaluator = BaselineEvaluator(config)\n",
    "    all_results = {}\n",
    "    \n",
    "    # Check if test file exists\n",
    "    test_file = None\n",
    "    test_files = [\n",
    "        f\"{config.data_dir}/test_clean.json\",\n",
    "        f\"{config.data_dir}/test.json\",\n",
    "        f\"{config.data_dir}/test.jsonl\"\n",
    "    ]\n",
    "    \n",
    "    for f in test_files:\n",
    "        if Path(f).exists():\n",
    "            test_file = f\n",
    "            print(f\"Found test file: {f}\")\n",
    "            break\n",
    "    \n",
    "    if not test_file:\n",
    "        print(\"⚠ No test file found, using validation set for evaluation\")\n",
    "        test_file = f\"{config.data_dir}/valid_clean.json\"\n",
    "    \n",
    "    # Evaluate Direct Fine-tuning\n",
    "    print(\"\\n1. Evaluating Direct Fine-tuning...\")\n",
    "    try:\n",
    "        direct_baseline = DirectFineTuningBaseline(config)\n",
    "        # Load trained model if exists\n",
    "        model_path = Path(config.output_dir) / \"direct_finetuning\" / \"final_model\"\n",
    "        if model_path.exists():\n",
    "            from peft import PeftModel\n",
    "            direct_baseline.model = PeftModel.from_pretrained(\n",
    "                direct_baseline.model, str(model_path)\n",
    "            )\n",
    "            print(\"  Loaded trained model\")\n",
    "        \n",
    "        direct_results = evaluator.evaluate_model(\n",
    "            direct_baseline,\n",
    "            test_file,\n",
    "            \"direct_finetuning\"\n",
    "        )\n",
    "        all_results[\"direct_finetuning\"] = direct_results\n",
    "        del direct_baseline\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed: {e}\")\n",
    "    \n",
    "    # Evaluate Retrieval\n",
    "    print(\"\\n2. Evaluating Retrieval-Augmented...\")\n",
    "    try:\n",
    "        retrieval_baseline = RetrievalAugmentedBaseline(config)\n",
    "        index_path = Path(config.output_dir) / \"retrieval_augmented\" / \"formal_index.faiss\"\n",
    "        if index_path.exists():\n",
    "            import faiss\n",
    "            retrieval_baseline.formal_index = faiss.read_index(str(index_path))\n",
    "            retrieval_baseline.informal_index = faiss.read_index(\n",
    "                str(Path(config.output_dir) / \"retrieval_augmented\" / \"informal_index.faiss\")\n",
    "            )\n",
    "            print(\"  Loaded existing indices\")\n",
    "            \n",
    "            # Reload texts\n",
    "            train_file = found_files.get('train')\n",
    "            if train_file:\n",
    "                with open(train_file, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    if content.strip().startswith('['):\n",
    "                        data = json.loads(content)\n",
    "                    else:\n",
    "                        f.seek(0)\n",
    "                        data = [json.loads(line) for line in f if line.strip()]\n",
    "                \n",
    "                for item in data:\n",
    "                    for inf_key in ['informal_statement', 'informal_stmt', 'informal']:\n",
    "                        if inf_key in item:\n",
    "                            for form_key in ['formal_statement', 'formal_stmt', 'formal']:\n",
    "                                if form_key in item:\n",
    "                                    retrieval_baseline.formal_texts.append(item[form_key])\n",
    "                                    retrieval_baseline.informal_texts.append(item[inf_key])\n",
    "                                    break\n",
    "                            break\n",
    "        else:\n",
    "            retrieval_baseline.build_index()\n",
    "        \n",
    "        retrieval_results = evaluator.evaluate_model(\n",
    "            retrieval_baseline,\n",
    "            test_file,\n",
    "            \"retrieval_augmented\"\n",
    "        )\n",
    "        all_results[\"retrieval_augmented\"] = retrieval_results\n",
    "        del retrieval_baseline\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed: {e}\")\n",
    "    \n",
    "    # Evaluate API\n",
    "    print(\"\\n3. Evaluating API Baseline...\")\n",
    "    try:\n",
    "        api_baseline = CommercialAPIBaseline(config)\n",
    "        api_results = evaluator.evaluate_model(\n",
    "            api_baseline,\n",
    "            test_file,\n",
    "            \"api_baseline\"\n",
    "        )\n",
    "        all_results[\"api_baseline\"] = api_results\n",
    "        del api_baseline\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed: {e}\")\n",
    "    \n",
    "    print(\"\\n✓ Evaluation complete!\")\n",
    "    \n",
    "    # Save combined results\n",
    "    if all_results:\n",
    "        results_dir = Path(config.output_dir) / \"evaluation_results\"\n",
    "        results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with open(results_dir / \"all_results.json\", 'w') as f:\n",
    "            json.dump(all_results, f, indent=2)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Evaluation failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cd164e4-fcb8-489c-b0bd-852f41d1c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Baseline Performance on Manual Dataset:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Direct Finetuning:\n",
      "  F→I:\n",
      "    BLEU:      0.0771\n",
      "    ROUGE-L:   0.2090\n",
      "    BERTScore: 0.8244\n",
      "  I→F:\n",
      "    BLEU:      0.0309\n",
      "    ROUGE-L:   0.1651\n",
      "    BERTScore: 0.7873\n",
      "\n",
      "Retrieval Augmented:\n",
      "  F→I:\n",
      "    BLEU:      0.0238\n",
      "    ROUGE-L:   0.1422\n",
      "    BERTScore: 0.8231\n",
      "  I→F:\n",
      "    BLEU:      0.0154\n",
      "    ROUGE-L:   0.1554\n",
      "    BERTScore: 0.8130\n",
      "\n",
      "Api Baseline:\n",
      "  F→I:\n",
      "    BLEU:      0.0483\n",
      "    ROUGE-L:   0.2235\n",
      "    BERTScore: 0.8053\n",
      "  I→F:\n",
      "    BLEU:      0.0320\n",
      "    ROUGE-L:   0.1401\n",
      "    BERTScore: 0.7875\n",
      "\n",
      "============================================================\n",
      "PHASE 1 COMPLETE!\n",
      "============================================================\n",
      "\n",
      "📊 Key Achievements:\n",
      "1. ✓ Loaded your manually extracted Lean 4 formal-informal pairs\n",
      "2. ✓ Trained Qwen2.5-Math model with QLoRA for efficient fine-tuning\n",
      "3. ✓ Built retrieval system with real mathematical theorems\n",
      "4. ✓ Established baselines with proper evaluation metrics\n",
      "\n",
      "🎯 Dataset Summary:\n",
      "• Training samples: 702 pairs\n",
      "• Column format detected: informal_statement / formal_statement\n",
      "\n",
      "🚀 Next Steps for Phase 2 (FIRMA):\n",
      "1. Use this dataset for FIRMA training\n",
      "2. Implement bidirectional translation with complexity control\n",
      "3. Compare FIRMA against these Qwen baselines\n",
      "4. Achieve superior performance through architectural innovations\n",
      "\n",
      "💡 Tips:\n",
      "• If results are low, check that train/valid/test files use consistent column names\n",
      "• Consider increasing training epochs if GPU memory allows\n",
      "• For better retrieval, use a math-specific embedding model\n",
      "\n",
      "============================================================\n",
      "SAVING DATASET STATISTICS\n",
      "============================================================\n",
      "✓ Statistics saved to baseline_output/dataset_stats.json\n",
      "\n",
      "Phase 1 notebook execution complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Display Results Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_dir = Path(config.output_dir) / \"evaluation_results\"\n",
    "\n",
    "if results_dir.exists():\n",
    "    # Load all results\n",
    "    all_results_file = results_dir / \"all_results.json\"\n",
    "    if all_results_file.exists():\n",
    "        with open(all_results_file, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nBaseline Performance on Manual Dataset:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for model_name, model_results in all_results.items():\n",
    "            print(f\"\\n{model_name.replace('_', ' ').title()}:\")\n",
    "            for direction in ['formal_to_informal', 'informal_to_formal']:\n",
    "                if direction in model_results:\n",
    "                    metrics = model_results[direction]\n",
    "                    dir_label = 'F→I' if direction == 'formal_to_informal' else 'I→F'\n",
    "                    print(f\"  {dir_label}:\")\n",
    "                    print(f\"    BLEU:      {metrics.get('bleu', 0):.4f}\")\n",
    "                    print(f\"    ROUGE-L:   {metrics.get('rougeL', 0):.4f}\")\n",
    "                    print(f\"    BERTScore: {metrics.get('bertscore_f1', 0):.4f}\")\n",
    "    else:\n",
    "        print(\"No results file found\")\n",
    "\n",
    "# Cell 10: Analysis and Next Steps\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 1 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n📊 Key Achievements:\")\n",
    "print(\"1. ✓ Loaded your manually extracted Lean 4 formal-informal pairs\")\n",
    "print(\"2. ✓ Trained Qwen2.5-Math model with QLoRA for efficient fine-tuning\")\n",
    "print(\"3. ✓ Built retrieval system with real mathematical theorems\")\n",
    "print(\"4. ✓ Established baselines with proper evaluation metrics\")\n",
    "\n",
    "print(\"\\n🎯 Dataset Summary:\")\n",
    "if 'train' in found_files:\n",
    "    print(f\"• Training samples: {len(train_data)} pairs\")\n",
    "print(f\"• Column format detected: {informal_key} / {formal_key}\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps for Phase 2 (FIRMA):\")\n",
    "print(\"1. Use this dataset for FIRMA training\")\n",
    "print(\"2. Implement bidirectional translation with complexity control\")\n",
    "print(\"3. Compare FIRMA against these Qwen baselines\")\n",
    "print(\"4. Achieve superior performance through architectural innovations\")\n",
    "\n",
    "print(\"\\n💡 Tips:\")\n",
    "print(\"• If results are low, check that train/valid/test files use consistent column names\")\n",
    "print(\"• Consider increasing training epochs if GPU memory allows\")\n",
    "print(\"• For better retrieval, use a math-specific embedding model\")\n",
    "\n",
    "# Cell 11: Save dataset statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stats = {\n",
    "    \"found_files\": {k: str(v) for k, v in found_files.items()},\n",
    "    \"train_samples\": len(train_data) if 'train_data' in locals() else 0,\n",
    "    \"column_format\": {\n",
    "        \"informal\": informal_key if 'informal_key' in locals() else None,\n",
    "        \"formal\": formal_key if 'formal_key' in locals() else None\n",
    "    },\n",
    "    \"gpu_config\": {\n",
    "        \"available\": torch.cuda.is_available(),\n",
    "        \"device_count\": torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
    "        \"memory_gb\": torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "stats_file = Path(config.output_dir) / \"dataset_stats.json\"\n",
    "with open(stats_file, 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "print(f\"✓ Statistics saved to {stats_file}\")\n",
    "print(\"\\nPhase 1 notebook execution complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50230471-e9e5-4963-a764-0e133f36f5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
